{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN835/hX6bm9PMSuUPz7jD2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9b3778c86744c0f81a9035a32a207ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50087fb728eb4d0baade37e9ad1425df",
              "IPY_MODEL_f2fb3ab66c924e66b080c95b81178f8e",
              "IPY_MODEL_cdd3692bd8a34d018195d1a963436462"
            ],
            "layout": "IPY_MODEL_929c33f931bd4d348ccfd7b78e1eff03"
          }
        },
        "50087fb728eb4d0baade37e9ad1425df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_247f9c50e5264a0dba6f8c5486b48509",
            "placeholder": "​",
            "style": "IPY_MODEL_3803957d5fcc47bf970d7778e53a79eb",
            "value": "100%"
          }
        },
        "f2fb3ab66c924e66b080c95b81178f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_670501de2e0f46c48b5dcc240a1b0c2b",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b66cf1c3480f4c159bc6240c4876e247",
            "value": 80
          }
        },
        "cdd3692bd8a34d018195d1a963436462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7eca2ae68344a048945870b6b9e8996",
            "placeholder": "​",
            "style": "IPY_MODEL_82e7c64290134e23ba3bcc502d8a98d4",
            "value": " 80/80 [00:36&lt;00:00,  2.27ba/s]"
          }
        },
        "929c33f931bd4d348ccfd7b78e1eff03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "247f9c50e5264a0dba6f8c5486b48509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3803957d5fcc47bf970d7778e53a79eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "670501de2e0f46c48b5dcc240a1b0c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b66cf1c3480f4c159bc6240c4876e247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7eca2ae68344a048945870b6b9e8996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e7c64290134e23ba3bcc502d8a98d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "747e88341dbc486390aee9585c684404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ef6b220b49142cfa4604e1d292af8ba",
              "IPY_MODEL_1761d0768ac549ac8032244406adfbb2",
              "IPY_MODEL_a48d9e3e660d419db53e267d24f95c2f"
            ],
            "layout": "IPY_MODEL_78f7b76804114a8cbc79e6d37ca9db24"
          }
        },
        "3ef6b220b49142cfa4604e1d292af8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8b05ee5412c4a57af61824f8c36c3f6",
            "placeholder": "​",
            "style": "IPY_MODEL_d689cd962543488b8d95685cc78e8376",
            "value": "100%"
          }
        },
        "1761d0768ac549ac8032244406adfbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077221b04a65422aa1ef7ef69286ce36",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_950d2c1f44224404af840dddfe7a6639",
            "value": 11
          }
        },
        "a48d9e3e660d419db53e267d24f95c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6864984cd5c48e5a907ff830a765798",
            "placeholder": "​",
            "style": "IPY_MODEL_a0184dbf075e444dbc80e7ab841efdf0",
            "value": " 11/11 [00:04&lt;00:00,  2.27ba/s]"
          }
        },
        "78f7b76804114a8cbc79e6d37ca9db24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b05ee5412c4a57af61824f8c36c3f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d689cd962543488b8d95685cc78e8376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "077221b04a65422aa1ef7ef69286ce36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "950d2c1f44224404af840dddfe7a6639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6864984cd5c48e5a907ff830a765798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0184dbf075e444dbc80e7ab841efdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/en2ko-ko2en-translator-mT5-small/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "szmDNko71tqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set notebook parameters"
      ],
      "metadata": {
        "id": "tm-IS9TOoSfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_name = 'en2ko-translator-mt5-small'\n",
        "run_name = 'baseline'"
      ],
      "metadata": {
        "id": "4Xt5ekSsoZ5d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisites"
      ],
      "metadata": {
        "id": "P1KUryBDS826"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/mt5-small-finetuned-en-to-ko_original\n",
        "# !rm -rf /content/wandb"
      ],
      "metadata": {
        "id": "nGFUJPolmhzk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets transformers sentencepiece sacrebleu folium==0.2.1 wandb"
      ],
      "metadata": {
        "id": "RIDQm6YMN7MI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# id = \"1J21-T8wYjlj-91CxtxEzrcE34CDt7CM3\"\n",
        "# gdown.download_folder(id=id, quiet=True, use_cookies=False)\n",
        "# !unzip -q /content/data/TS1.zip -d /content/data\n",
        "# !unzip -q /content/data/VS1.zip -d /content/data"
      ],
      "metadata": {
        "id": "STwW2vB4Nn2X"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set WandB "
      ],
      "metadata": {
        "id": "-SYiaMTojqod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7qDzf-ajvlP",
        "outputId": "11d09dd5-836e-4f73-e6ea-2908d1c7404a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdotsnangles\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_PROJECT=$project_name\n",
        "%env WANDB_LOG_MODEL=true\n",
        "%env WANDB_WATCH=all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_sIlAvvmzmw",
        "outputId": "a67a2ec7-044a-4ce2-9b8d-ab3f9f06f60e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_PROJECT=en2ko-translator-mt5-small\n",
            "env: WANDB_LOG_MODEL=true\n",
            "env: WANDB_WATCH=all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection"
      ],
      "metadata": {
        "id": "HUg3W8tlTIs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = 'google/mt5-small'"
      ],
      "metadata": {
        "id": "fqj75pbLR4am"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import stuff"
      ],
      "metadata": {
        "id": "cUS1L0gQTDWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, gdown\n",
        "import pandas as pd\n",
        "from datasets import Dataset, load_metric\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n"
      ],
      "metadata": {
        "id": "YdxTLx5GN5Eq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./data/train.csv')\n",
        "val_df = pd.read_csv('./data/val.csv')"
      ],
      "metadata": {
        "id": "yy9cR0OJOToH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=False)"
      ],
      "metadata": {
        "id": "_4TJocDGRs5f"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure token length"
      ],
      "metadata": {
        "id": "YV3I14qlfNjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_len(sample):\n",
        "    return len(tokenizer.encode(sample))"
      ],
      "metadata": {
        "id": "qN4QG9JvVtBM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_prefix = \"translate English to Korean: \"\n",
        "\n",
        "print('length of src_prefix:', measure_len(src_prefix))\n",
        "print(tokenizer.encode(src_prefix))\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer.encode(src_prefix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km6c--bWXRZ8",
        "outputId": "ffec4c60-f3e1-49c3-ab86-a455973c03e6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of src_prefix: 7\n",
            "[37194, 5413, 288, 259, 37209, 267, 1]\n",
            "[37194, 5413, 288, 259, 37209, 267, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_en_len = train_df['en'].apply(measure_len)\n",
        "train_df_ko_len = train_df['ko_original'].apply(measure_len)\n",
        "val_df_en_len = val_df['en'].apply(measure_len)\n",
        "val_df_ko_len = val_df['ko_original'].apply(measure_len)"
      ],
      "metadata": {
        "id": "yzUzczwnWJsq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(train_df_en_len)+7, max(train_df_ko_len), max(val_df_en_len)+7, max(val_df_ko_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAGxXOMkWlwz",
        "outputId": "f730ff4a-f44e-4644-ef7c-0b6f207b9f45"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(117, 154, 99, 102)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### df to ds"
      ],
      "metadata": {
        "id": "_VvDz3dbfVP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GuObstwNWwZ",
        "outputId": "4818ffbd-7e13-463a-f348-ac4df50f55c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['en', 'ko_original'],\n",
              "     num_rows: 79979\n",
              " }), Dataset({\n",
              "     features: ['en', 'ko_original'],\n",
              "     num_rows: 10131\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "train_ds = Dataset.from_pandas(train_df)\n",
        "val_ds = Dataset.from_pandas(val_df)\n",
        "train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "for e in train_ds:\n",
        "    print(e)\n",
        "    idx += 1\n",
        "    if idx == 2:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OvpUAf3aZiL",
        "outputId": "63531a14-783e-4942-cd31-0376610fa4ca"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'en': 'The comparators 1235 and 1237 may be expressed as a Relu activation function or a sigmoid function according to a setting.', 'ko_original': '비교기(1235 및 1237)는 설정에 따라 Relu 활성함수로 나타낼 수 있으며, 시그모이드 함수로 나타낼 수도 있다.'}\n",
            "{'en': 'The server 320 may input a source image to the analysis model DB 325 and receive object information output from the training model.', 'ko_original': '서버(320)는 분석 모델 DB(325)에 소스 영상을 입력하고, 학습 모델에서 출력하는 객체 정보를 수신할 수 있다.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "L1MWBLv4fcm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_lang = \"en\"\n",
        "target_lang = \"ko_original\"\n",
        "prefix = \"translate English to Korean: \"\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example for example in examples[source_lang]]\n",
        "    targets = [example for example in examples[target_lang]]\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=160, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "5Lv5xOHbVO4G"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test preprocess_function"
      ],
      "metadata": {
        "id": "w-xGqutYiZjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKPpEDKMcY1P",
        "outputId": "2793c9ae-9e86-4301-c1d8-5a82a49c2cf4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': ['The comparators 1235 and 1237 may be expressed as a Relu activation function or a sigmoid function according to a setting.',\n",
              "  'The server 320 may input a source image to the analysis model DB 325 and receive object information output from the training model.',\n",
              "  'The block shape and the split shape may be differently determined for each picture or slice, or differently determined for each largest coding unit.'],\n",
              " 'ko_original': ['비교기(1235 및 1237)는 설정에 따라 Relu 활성함수로 나타낼 수 있으며, 시그모이드 함수로 나타낼 수도 있다.',\n",
              "  '서버(320)는 분석 모델 DB(325)에 소스 영상을 입력하고, 학습 모델에서 출력하는 객체 정보를 수신할 수 있다.',\n",
              "  '블록 형태 및 분할 형태는 픽처 또는 슬라이스마다 상이하게 결정되거나, 각각의 최대 부호화 단위마다 상이하게 결정될 수도 있다.']}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_test = preprocess_function(train_ds[:3])\n",
        "print('input id', preprocess_test.input_ids[0])\n",
        "print(tokenizer.decode(preprocess_test.input_ids[0]), '\\n')\n",
        "print('attention mask', preprocess_test.attention_mask[0], '\\n')\n",
        "print('label', preprocess_test.labels[0])\n",
        "print(tokenizer.decode(preprocess_test.labels[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSVtadpAVO79",
        "outputId": "ccb2b04f-73d3-481c-823e-89ae0887e8fd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input id [37194, 5413, 288, 259, 37209, 267, 486, 39959, 19002, 259, 175510, 305, 259, 162249, 1432, 390, 17385, 345, 527, 259, 262, 788, 1696, 259, 97359, 2835, 631, 259, 262, 2002, 1233, 525, 2835, 259, 18775, 288, 259, 262, 36577, 260, 1]\n",
            "translate English to Korean: The comparators 1235 and 1237 may be expressed as a Relu activation function or a sigmoid function according to a setting.</s> \n",
            "\n",
            "attention mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
            "\n",
            "label [259, 53789, 1622, 312, 175510, 259, 5593, 644, 101294, 988, 30957, 118645, 259, 18490, 788, 1696, 63019, 3353, 12482, 2277, 1235, 49303, 125462, 1566, 3083, 19023, 261, 6463, 11051, 6763, 63362, 15331, 2277, 1235, 49303, 125462, 259, 44830, 3632, 260, 1]\n",
            "비교기(1235 및 1237)는 설정에 따라 Relu 활성함수로 나타낼 수 있으며, 시그모이드 함수로 나타낼 수도 있다.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = train_ds.map(preprocess_function, batched=True)\n",
        "tokenized_val = val_ds.map(preprocess_function, batched=True)\n",
        "tokenized_train, tokenized_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "f9b3778c86744c0f81a9035a32a207ca",
            "50087fb728eb4d0baade37e9ad1425df",
            "f2fb3ab66c924e66b080c95b81178f8e",
            "cdd3692bd8a34d018195d1a963436462",
            "929c33f931bd4d348ccfd7b78e1eff03",
            "247f9c50e5264a0dba6f8c5486b48509",
            "3803957d5fcc47bf970d7778e53a79eb",
            "670501de2e0f46c48b5dcc240a1b0c2b",
            "b66cf1c3480f4c159bc6240c4876e247",
            "b7eca2ae68344a048945870b6b9e8996",
            "82e7c64290134e23ba3bcc502d8a98d4",
            "747e88341dbc486390aee9585c684404",
            "3ef6b220b49142cfa4604e1d292af8ba",
            "1761d0768ac549ac8032244406adfbb2",
            "a48d9e3e660d419db53e267d24f95c2f",
            "78f7b76804114a8cbc79e6d37ca9db24",
            "f8b05ee5412c4a57af61824f8c36c3f6",
            "d689cd962543488b8d95685cc78e8376",
            "077221b04a65422aa1ef7ef69286ce36",
            "950d2c1f44224404af840dddfe7a6639",
            "a6864984cd5c48e5a907ff830a765798",
            "a0184dbf075e444dbc80e7ab841efdf0"
          ]
        },
        "id": "uhQB-xQ1VO_N",
        "outputId": "ef01f8fb-5c4e-422d-ed0e-5e08274c7486"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/80 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9b3778c86744c0f81a9035a32a207ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "747e88341dbc486390aee9585c684404"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['en', 'ko_original', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 79979\n",
              " }), Dataset({\n",
              "     features: ['en', 'ko_original', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 10131\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load metric"
      ],
      "metadata": {
        "id": "MnuWgfC8igUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"sacrebleu\")\n",
        "fake_preds = [\"hello there\", \"general kenobi\"]\n",
        "fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n",
        "metric.compute(predictions=fake_preds, references=fake_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QjQuaf9O4YJ",
        "outputId": "6acfe3fe-783b-4b12-ab53-c48b933f31fc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bp': 1.0,\n",
              " 'counts': [4, 2, 0, 0],\n",
              " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
              " 'ref_len': 4,\n",
              " 'score': 0.0,\n",
              " 'sys_len': 4,\n",
              " 'totals': [4, 2, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check and Load model"
      ],
      "metadata": {
        "id": "v7YFYMPailL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(model_ckpt)\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyw5xcgqQUaW",
        "outputId": "c96d638b-d564-43e9-ffd8-edc9a61519b3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MT5Config {\n",
              "  \"_name_or_path\": \"google/mt5-small\",\n",
              "  \"architectures\": [\n",
              "    \"MT5ForConditionalGeneration\"\n",
              "  ],\n",
              "  \"d_ff\": 1024,\n",
              "  \"d_kv\": 64,\n",
              "  \"d_model\": 512,\n",
              "  \"decoder_start_token_id\": 0,\n",
              "  \"dense_act_fn\": \"gelu_new\",\n",
              "  \"dropout_rate\": 0.1,\n",
              "  \"eos_token_id\": 1,\n",
              "  \"feed_forward_proj\": \"gated-gelu\",\n",
              "  \"initializer_factor\": 1.0,\n",
              "  \"is_encoder_decoder\": true,\n",
              "  \"is_gated_act\": true,\n",
              "  \"layer_norm_epsilon\": 1e-06,\n",
              "  \"model_type\": \"mt5\",\n",
              "  \"num_decoder_layers\": 8,\n",
              "  \"num_heads\": 6,\n",
              "  \"num_layers\": 8,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"relative_attention_max_distance\": 128,\n",
              "  \"relative_attention_num_buckets\": 32,\n",
              "  \"tie_word_embeddings\": false,\n",
              "  \"tokenizer_class\": \"T5Tokenizer\",\n",
              "  \"transformers_version\": \"4.21.0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 250112\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_config(config)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_9rSeWrRKfp",
        "outputId": "1592f6f5-2cb2-4356-a267-32ae81497b07"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MT5ForConditionalGeneration(\n",
              "  (shared): Embedding(250112, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(250112, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 6)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(250112, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 6)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
              "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output_dir = \n",
        "# overwrite_output_dir = \n",
        "# do_train = \n",
        "# do_eval = \n",
        "# do_predict = \n",
        "# evaluation_strategy = \n",
        "# prediction_loss_only = \n",
        "# per_device_train_batch_size = \n",
        "# per_device_eval_batch_size = \n",
        "# per_gpu_train_batch_size = \n",
        "# per_gpu_eval_batch_size = \n",
        "# gradient_accumulation_steps = \n",
        "# eval_accumulation_steps = \n",
        "# eval_delay = \n",
        "# learning_rate = \n",
        "# weight_decay = \n",
        "# adam_beta1 = \n",
        "# adam_beta2 = \n",
        "# adam_epsilon = \n",
        "# max_grad_norm = \n",
        "# num_train_epochs = \n",
        "# max_steps = \n",
        "# lr_scheduler_type = \n",
        "# warmup_ratio = \n",
        "# warmup_steps = \n",
        "# log_level = \n",
        "# log_level_replica = \n",
        "# log_on_each_node = \n",
        "# logging_dir = \n",
        "# logging_strategy = \n",
        "# logging_first_step = \n",
        "# logging_steps = \n",
        "# logging_nan_inf_filter = \n",
        "# save_strategy = \n",
        "# save_steps = \n",
        "# save_total_limit = \n",
        "# save_on_each_node = \n",
        "# no_cuda = \n",
        "# seed = \n",
        "# data_seed = \n",
        "# jit_mode_eval = \n",
        "# use_ipex = \n",
        "# bf16 = \n",
        "# fp16 = \n",
        "# fp16_opt_level = \n",
        "# half_precision_backend = \n",
        "# bf16_full_eval = \n",
        "# fp16_full_eval = \n",
        "# tf32 = \n",
        "# local_rank = \n",
        "# xpu_backend = \n",
        "# tpu_num_cores = \n",
        "# tpu_metrics_debug = \n",
        "# debug = \n",
        "# dataloader_drop_last = \n",
        "# eval_steps = \n",
        "# dataloader_num_workers = \n",
        "# past_index = \n",
        "# run_name = \n",
        "# disable_tqdm = \n",
        "# remove_unused_columns = \n",
        "# label_names = \n",
        "# load_best_model_at_end = \n",
        "# metric_for_best_model = \n",
        "# greater_is_better = \n",
        "# ignore_data_skip = \n",
        "# sharded_ddp = \n",
        "# fsdp = \n",
        "# fsdp_min_num_params = \n",
        "# fsdp_transformer_layer_cls_to_wrap = \n",
        "# deepspeed = \n",
        "# label_smoothing_factor = \n",
        "# optim = \n",
        "# adafactor = \n",
        "# group_by_length = \n",
        "# length_column_name = \n",
        "# report_to = \n",
        "# ddp_find_unused_parameters = \n",
        "# ddp_bucket_cap_mb = \n",
        "# dataloader_pin_memory = \n",
        "# skip_memory_metrics = \n",
        "# use_legacy_prediction_loop = \n",
        "# push_to_hub = \n",
        "# resume_from_checkpoint = \n",
        "# hub_model_id = \n",
        "# hub_strategy = \n",
        "# hub_token = \n",
        "# hub_private_repo = \n",
        "# gradient_checkpointing = \n",
        "# include_inputs_for_metrics = \n",
        "# fp16_backend = \n",
        "# push_to_hub_model_id = \n",
        "# push_to_hub_organization = \n",
        "# push_to_hub_token = \n",
        "# mp_parameters = \n",
        "# auto_find_batch_size = \n",
        "# full_determinism = \n",
        "# torchdynamo = \n",
        "# ray_scope = \n",
        "# sortish_sampler = \n",
        "# predict_with_generate = \n",
        "# generation_max_length = \n",
        "# generation_num_beams = "
      ],
      "metadata": {
        "id": "eYwlo37NuMSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "model_name = model_ckpt.split(\"/\")[-1]\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=False,\n",
        "    report_to='wandb',\n",
        "    run_name=run_name\n",
        ")"
      ],
      "metadata": {
        "id": "Tzq1F-lNRpLN"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "1XKuNNiqfwqH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "metadata": {
        "id": "XKXf0rA-gGPE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "CFZFoERSgMoX"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RlgQ_NgChMRy",
        "outputId": "77c568a1-bdf7-4bae-bfd4-8fb86435b34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 79979\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 9998\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220801_134939-1nim0nmr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dotsnangles/en2ko-translator-mt5-small/runs/1nim0nmr\" target=\"_blank\">baseline</a></strong> to <a href=\"https://wandb.ai/dotsnangles/en2ko-translator-mt5-small\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7586' max='9998' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7586/9998 49:38 < 15:47, 2.55 it/s, Epoch 0.76/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-1000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1000/special_tokens_map.json\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-1500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-2000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2000/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-500] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-2500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2500/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-1000] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-3000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3000/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-1500] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-3500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3500/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-2000] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-4000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-4000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-4000/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-2500] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-4500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-4500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-4500/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-3000] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-5000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5000/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-3500] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-5500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5500/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-4000] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-6000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6000/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-4500] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-6500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6500/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-5000] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-7000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7000/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-5500] due to args.save_total_limit\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-7500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7500/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-6000] due to args.save_total_limit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gVjqZZr9nWFD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}