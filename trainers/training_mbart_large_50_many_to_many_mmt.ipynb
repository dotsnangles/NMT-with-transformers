{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_mbart-large-50-many-to-many-mmt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNaafZj4Vy1mGiDvWnjXPd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/NMT-with-transformers/blob/master/training_mbart_large_50_many_to_many_mmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/mt5-small-finetuned-en-to-ko /content/wandb"
      ],
      "metadata": {
        "id": "nGFUJPolmhzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "szmDNko71tqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set notebook parameters"
      ],
      "metadata": {
        "id": "tm-IS9TOoSfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_name = 'mBart test'\n",
        "\n",
        "project_name = 'en2ko-translator_mbart_large_50_many_to_many_mmt'\n",
        "\n",
        "# val_ds_len = 256 # max 10131\n",
        "\n",
        "num_train_epochs = 15\n",
        "batch_size = 4\n",
        "gradient_accumulation_steps = 4\n",
        "\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 0.01\n",
        "\n",
        "lr_scheduler_type = 'cosine'\n",
        "warmup_ratio = 0.1\n",
        "\n",
        "predict_with_generate = False\n",
        "generation_max_length = 256\n",
        "\n",
        "early_stopping_patience = 3\n",
        "save_total_limit = 5\n",
        "\n",
        "load_best_model_at_end = True\n",
        "metric_for_best_model='eval_loss'\n",
        "\n",
        "save_strategy = \"steps\"\n",
        "evaluation_strategy = \"steps\"\n",
        "save_steps = 1250\n",
        "eval_steps = 1250\n",
        "\n",
        "logging_strategy = \"steps\"\n",
        "logging_first_step = True \n",
        "logging_steps = 500\n",
        "\n",
        "fp16 = False"
      ],
      "metadata": {
        "id": "4Xt5ekSsoZ5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisites"
      ],
      "metadata": {
        "id": "P1KUryBDS826"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets transformers sentencepiece sacrebleu folium wandb"
      ],
      "metadata": {
        "id": "RIDQm6YMN7MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "id = \"1J21-T8wYjlj-91CxtxEzrcE34CDt7CM3\"\n",
        "gdown.download_folder(id=id, quiet=True, use_cookies=False)\n",
        "!unzip -q /content/data/TS1.zip -d /content/data\n",
        "!unzip -q /content/data/VS1.zip -d /content/data"
      ],
      "metadata": {
        "id": "STwW2vB4Nn2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set WandB "
      ],
      "metadata": {
        "id": "-SYiaMTojqod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "p7qDzf-ajvlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_PROJECT=$project_name\n",
        "%env WANDB_LOG_MODEL=true\n",
        "%env WANDB_WATCH=all"
      ],
      "metadata": {
        "id": "z_sIlAvvmzmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection"
      ],
      "metadata": {
        "id": "HUg3W8tlTIs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = 'facebook/mbart-large-50-many-to-many-mmt'"
      ],
      "metadata": {
        "id": "fqj75pbLR4am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import stuff"
      ],
      "metadata": {
        "id": "cUS1L0gQTDWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, gdown\n",
        "import pandas as pd\n",
        "from datasets import Dataset, load_metric\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n"
      ],
      "metadata": {
        "id": "YdxTLx5GN5Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./data/train.csv')\n",
        "val_df = pd.read_csv('./data/val.csv')"
      ],
      "metadata": {
        "id": "yy9cR0OJOToH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)\n",
        "tokenizer.src_lang = 'en-XX'\n",
        "tokenizer.tgt_lang ='ko_KR'"
      ],
      "metadata": {
        "id": "_4TJocDGRs5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure token length"
      ],
      "metadata": {
        "id": "YV3I14qlfNjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_len(sample):\n",
        "    return len(tokenizer.encode(sample))"
      ],
      "metadata": {
        "id": "qN4QG9JvVtBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# src_prefix = \"translate English to Korean: \"\n",
        "\n",
        "# print('length of src_prefix:', measure_len(src_prefix))\n",
        "# print(tokenizer.encode(src_prefix))\n",
        "# with tokenizer.as_target_tokenizer():\n",
        "#     print(tokenizer.encode(src_prefix))"
      ],
      "metadata": {
        "id": "km6c--bWXRZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_en_len = train_df['en'].apply(measure_len)\n",
        "train_df_ko_len = train_df['ko'].apply(measure_len)\n",
        "val_df_en_len = val_df['en'].apply(measure_len)\n",
        "val_df_ko_len = val_df['ko'].apply(measure_len)"
      ],
      "metadata": {
        "id": "yzUzczwnWJsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(train_df_en_len)+7, max(train_df_ko_len), max(val_df_en_len)+7, max(val_df_ko_len)"
      ],
      "metadata": {
        "id": "MAGxXOMkWlwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### df to ds"
      ],
      "metadata": {
        "id": "_VvDz3dbfVP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GuObstwNWwZ"
      },
      "outputs": [],
      "source": [
        "train_ds = Dataset.from_pandas(train_df)\n",
        "val_ds = Dataset.from_pandas(val_df)\n",
        "# .shuffle(seed=42)[:val_ds_len]\n",
        "# val_ds = Dataset.from_dict(val_ds)\n",
        "train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "for e in train_ds:\n",
        "    print(e)\n",
        "    idx += 1\n",
        "    if idx == 2:\n",
        "        break"
      ],
      "metadata": {
        "id": "8OvpUAf3aZiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "L1MWBLv4fcm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_lang = \"en\"\n",
        "target_lang = \"ko\"\n",
        "prefix = \"translate English to Korean: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example for example in examples[source_lang]]\n",
        "    targets = [example for example in examples[target_lang]]\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=160, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "5Lv5xOHbVO4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test preprocess_function"
      ],
      "metadata": {
        "id": "w-xGqutYiZjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[:3]"
      ],
      "metadata": {
        "id": "iKPpEDKMcY1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_test = preprocess_function(train_ds[:3])\n",
        "print('input id', preprocess_test.input_ids[0])\n",
        "print(tokenizer.decode(preprocess_test.input_ids[0]), '\\n')\n",
        "print('attention mask', preprocess_test.attention_mask[0], '\\n')\n",
        "print('label', preprocess_test.labels[0])\n",
        "print(tokenizer.decode(preprocess_test.labels[0]))"
      ],
      "metadata": {
        "id": "CSVtadpAVO79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = train_ds.map(preprocess_function, batched=True)\n",
        "tokenized_val = val_ds.map(preprocess_function, batched=True)\n",
        "tokenized_train, tokenized_val"
      ],
      "metadata": {
        "id": "uhQB-xQ1VO_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load metric"
      ],
      "metadata": {
        "id": "MnuWgfC8igUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"sacrebleu\")\n",
        "# fake_preds = [\"hello there\", \"general kenobi\"]\n",
        "# fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n",
        "# metric.compute(predictions=fake_preds, references=fake_labels)"
      ],
      "metadata": {
        "id": "_QjQuaf9O4YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "metadata": {
        "id": "XKXf0rA-gGPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check and Load model"
      ],
      "metadata": {
        "id": "v7YFYMPailL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "pyw5xcgqQUaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_config(config)"
      ],
      "metadata": {
        "id": "q_9rSeWrRKfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = model_ckpt.split(\"/\")[-1]\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
        "    # report_to='wandb',\n",
        "    run_name=run_name,\n",
        "\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "\n",
        "    # predict_with_generate=predict_with_generate,\n",
        "    # generation_max_length=generation_max_length,\n",
        "\n",
        "    save_total_limit=save_total_limit,\n",
        "\n",
        "    load_best_model_at_end=load_best_model_at_end,\n",
        "    metric_for_best_model=metric_for_best_model,\n",
        "    \n",
        "    save_strategy=save_strategy,\n",
        "    evaluation_strategy=evaluation_strategy,\n",
        "    # save_steps=save_steps,\n",
        "    # eval_steps=eval_steps,\n",
        "\n",
        "    logging_strategy=logging_strategy,\n",
        "    logging_first_step=logging_first_step, \n",
        "    logging_steps=logging_steps,\n",
        "    \n",
        "    fp16=fp16,\n",
        ")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "# es = EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)"
      ],
      "metadata": {
        "id": "Tzq1F-lNRpLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    # callbacks=[es],\n",
        ")"
      ],
      "metadata": {
        "id": "CFZFoERSgMoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "RlgQ_NgChMRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('./save_model')"
      ],
      "metadata": {
        "id": "vqenuXm6DCb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('./save_model')"
      ],
      "metadata": {
        "id": "jncxdJuWX3iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained('./save_model')"
      ],
      "metadata": {
        "id": "AtT8a1xuX3mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Seq2SeqTrainingArguments(\n",
        "    'eval',\n",
        "    per_device_eval_batch_size=16,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=256,\n",
        ")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "lTjEH5vcX3qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    # train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "n3rFpv55X3tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "-soShdI_X3wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N6mJlEtVX3zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JNZKEwXoX399"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}