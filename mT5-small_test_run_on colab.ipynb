{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOE03G4Ha+OFhtuVMw+wxtv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f009ddb1e02b41ae814f8877a3eb39cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d20148c31e4e4bc4b1d459e5a583e5ca",
              "IPY_MODEL_c2b60ad5702d4067be8140e0ebb76fd3",
              "IPY_MODEL_356a637504c3490887f4ca87ac89fd9d"
            ],
            "layout": "IPY_MODEL_0b1a3b8d994a4d52b92131c09bf66bd0"
          }
        },
        "d20148c31e4e4bc4b1d459e5a583e5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d58869b913c14840a93d9a1bc2e4acbe",
            "placeholder": "​",
            "style": "IPY_MODEL_c276c9e132274f42bafeb097772a4e4c",
            "value": "100%"
          }
        },
        "c2b60ad5702d4067be8140e0ebb76fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ee6cd1719ab408a9c8ae779efe80518",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89608d0e79ad405ca41205316fcb2f87",
            "value": 80
          }
        },
        "356a637504c3490887f4ca87ac89fd9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c77d6b89484ca4a05c3b6ba4aae5bc",
            "placeholder": "​",
            "style": "IPY_MODEL_2ff25790b5714a5591aca9ba63c0232d",
            "value": " 80/80 [00:34&lt;00:00,  2.37ba/s]"
          }
        },
        "0b1a3b8d994a4d52b92131c09bf66bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58869b913c14840a93d9a1bc2e4acbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c276c9e132274f42bafeb097772a4e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ee6cd1719ab408a9c8ae779efe80518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89608d0e79ad405ca41205316fcb2f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96c77d6b89484ca4a05c3b6ba4aae5bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff25790b5714a5591aca9ba63c0232d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "820a57d625fa4a9f8fda5c1fc1aac56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4101b92120a943709e2e6765df6d5aa6",
              "IPY_MODEL_e3b193fbfe7e4cd9bd363692ff88c1dd",
              "IPY_MODEL_a975ac0ec7f040c9ba86e1b00aeba866"
            ],
            "layout": "IPY_MODEL_d6a890abf12a48a49c58815aa4cd264e"
          }
        },
        "4101b92120a943709e2e6765df6d5aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15522196e104c1887f50c75b284682b",
            "placeholder": "​",
            "style": "IPY_MODEL_1e74af611db74446a1919ba909a67b12",
            "value": "100%"
          }
        },
        "e3b193fbfe7e4cd9bd363692ff88c1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ccf19928b9f409496ee05c9d3cadbaf",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_435165d1ba454725af7e958b87cfa520",
            "value": 11
          }
        },
        "a975ac0ec7f040c9ba86e1b00aeba866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb143de08a61404396c6f46c38b039f9",
            "placeholder": "​",
            "style": "IPY_MODEL_67840db7811d4ec5a100791ddd797aa5",
            "value": " 11/11 [00:04&lt;00:00,  2.33ba/s]"
          }
        },
        "d6a890abf12a48a49c58815aa4cd264e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e15522196e104c1887f50c75b284682b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e74af611db74446a1919ba909a67b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ccf19928b9f409496ee05c9d3cadbaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "435165d1ba454725af7e958b87cfa520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb143de08a61404396c6f46c38b039f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67840db7811d4ec5a100791ddd797aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotsnangles/en2ko-ko2en-translator-mT5-small/blob/master/mT5-small_test_run_on%20colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/mt5-small-finetuned-en-to-ko_original /content/wandb"
      ],
      "metadata": {
        "id": "nGFUJPolmhzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szmDNko71tqn",
        "outputId": "1465df3b-24ba-4627-a275-2ff3e687bffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug  2 09:04:22 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set notebook parameters"
      ],
      "metadata": {
        "id": "tm-IS9TOoSfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_name = 'test run 005'\n",
        "\n",
        "project_name = 'en2ko-translator-mt5-small'\n",
        "\n",
        "# val_ds_len = 256 # max 10131\n",
        "\n",
        "num_train_epochs = 15\n",
        "batch_size = 4\n",
        "gradient_accumulation_steps = 4\n",
        "\n",
        "learning_rate = 2e-5\n",
        "weight_decay = 0.01\n",
        "\n",
        "lr_scheduler_type = 'cosine'\n",
        "warmup_ratio = 0.1\n",
        "\n",
        "predict_with_generate = False\n",
        "generation_max_length = 256\n",
        "\n",
        "early_stopping_patience = 3\n",
        "save_total_limit = 5\n",
        "\n",
        "load_best_model_at_end = True\n",
        "metric_for_best_model='eval_loss'\n",
        "\n",
        "save_strategy = \"steps\"\n",
        "evaluation_strategy = \"steps\"\n",
        "save_steps = 1250\n",
        "eval_steps = 1250\n",
        "\n",
        "logging_strategy = \"steps\"\n",
        "logging_first_step = True \n",
        "logging_steps = 500\n",
        "\n",
        "fp16 = False"
      ],
      "metadata": {
        "id": "4Xt5ekSsoZ5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prerequisites"
      ],
      "metadata": {
        "id": "P1KUryBDS826"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets transformers sentencepiece sacrebleu folium wandb"
      ],
      "metadata": {
        "id": "RIDQm6YMN7MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import gdown\n",
        "# id = \"1J21-T8wYjlj-91CxtxEzrcE34CDt7CM3\"\n",
        "# gdown.download_folder(id=id, quiet=True, use_cookies=False)\n",
        "# !unzip -q /content/data/TS1.zip -d /content/data\n",
        "# !unzip -q /content/data/VS1.zip -d /content/data"
      ],
      "metadata": {
        "id": "STwW2vB4Nn2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set WandB "
      ],
      "metadata": {
        "id": "-SYiaMTojqod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7qDzf-ajvlP",
        "outputId": "b9afe790-b09f-438c-d8cd-6bf7d957f77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdotsnangles\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_PROJECT=$project_name\n",
        "%env WANDB_LOG_MODEL=true\n",
        "%env WANDB_WATCH=all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_sIlAvvmzmw",
        "outputId": "63b7471c-fc08-49ed-d171-6a6168ee7916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_PROJECT=en2ko-translator-mt5-small\n",
            "env: WANDB_LOG_MODEL=true\n",
            "env: WANDB_WATCH=all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection"
      ],
      "metadata": {
        "id": "HUg3W8tlTIs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = 'google/mt5-small'"
      ],
      "metadata": {
        "id": "fqj75pbLR4am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import stuff"
      ],
      "metadata": {
        "id": "cUS1L0gQTDWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, gdown\n",
        "import pandas as pd\n",
        "from datasets import Dataset, load_metric\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n"
      ],
      "metadata": {
        "id": "YdxTLx5GN5Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./data/train.csv')\n",
        "val_df = pd.read_csv('./data/val.csv')"
      ],
      "metadata": {
        "id": "yy9cR0OJOToH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, use_fast=False)"
      ],
      "metadata": {
        "id": "_4TJocDGRs5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure token length"
      ],
      "metadata": {
        "id": "YV3I14qlfNjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_len(sample):\n",
        "    return len(tokenizer.encode(sample))"
      ],
      "metadata": {
        "id": "qN4QG9JvVtBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_prefix = \"translate English to Korean: \"\n",
        "\n",
        "print('length of src_prefix:', measure_len(src_prefix))\n",
        "print(tokenizer.encode(src_prefix))\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    print(tokenizer.encode(src_prefix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km6c--bWXRZ8",
        "outputId": "1490ec40-21a4-496e-9603-381fda55c0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of src_prefix: 7\n",
            "[37194, 5413, 288, 259, 37209, 267, 1]\n",
            "[37194, 5413, 288, 259, 37209, 267, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_en_len = train_df['en'].apply(measure_len)\n",
        "train_df_ko_len = train_df['ko_original'].apply(measure_len)\n",
        "val_df_en_len = val_df['en'].apply(measure_len)\n",
        "val_df_ko_len = val_df['ko_original'].apply(measure_len)"
      ],
      "metadata": {
        "id": "yzUzczwnWJsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(train_df_en_len)+7, max(train_df_ko_len), max(val_df_en_len)+7, max(val_df_ko_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAGxXOMkWlwz",
        "outputId": "6bdbf67f-423d-4a16-ffb6-c09686b5a90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(117, 154, 99, 102)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### df to ds"
      ],
      "metadata": {
        "id": "_VvDz3dbfVP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GuObstwNWwZ",
        "outputId": "32b4652b-9ab6-4360-ac3b-a831819c07ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['en', 'ko_original'],\n",
              "     num_rows: 79979\n",
              " }), Dataset({\n",
              "     features: ['en', 'ko_original'],\n",
              "     num_rows: 10131\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_ds = Dataset.from_pandas(train_df)\n",
        "val_ds = Dataset.from_pandas(val_df)\n",
        "# .shuffle(seed=42)[:val_ds_len]\n",
        "# val_ds = Dataset.from_dict(val_ds)\n",
        "train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0\n",
        "for e in train_ds:\n",
        "    print(e)\n",
        "    idx += 1\n",
        "    if idx == 2:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OvpUAf3aZiL",
        "outputId": "4aae893f-3ff6-4585-dc94-0dd9ae4b62d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'en': 'The comparators 1235 and 1237 may be expressed as a Relu activation function or a sigmoid function according to a setting.', 'ko_original': '비교기(1235 및 1237)는 설정에 따라 Relu 활성함수로 나타낼 수 있으며, 시그모이드 함수로 나타낼 수도 있다.'}\n",
            "{'en': 'The server 320 may input a source image to the analysis model DB 325 and receive object information output from the training model.', 'ko_original': '서버(320)는 분석 모델 DB(325)에 소스 영상을 입력하고, 학습 모델에서 출력하는 객체 정보를 수신할 수 있다.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "L1MWBLv4fcm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_lang = \"en\"\n",
        "target_lang = \"ko_original\"\n",
        "prefix = \"translate English to Korean: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example for example in examples[source_lang]]\n",
        "    targets = [example for example in examples[target_lang]]\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=160, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "5Lv5xOHbVO4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test preprocess_function"
      ],
      "metadata": {
        "id": "w-xGqutYiZjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKPpEDKMcY1P",
        "outputId": "cd3888f8-613e-43a7-e60e-ed2bf27637c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': ['The comparators 1235 and 1237 may be expressed as a Relu activation function or a sigmoid function according to a setting.',\n",
              "  'The server 320 may input a source image to the analysis model DB 325 and receive object information output from the training model.',\n",
              "  'The block shape and the split shape may be differently determined for each picture or slice, or differently determined for each largest coding unit.'],\n",
              " 'ko_original': ['비교기(1235 및 1237)는 설정에 따라 Relu 활성함수로 나타낼 수 있으며, 시그모이드 함수로 나타낼 수도 있다.',\n",
              "  '서버(320)는 분석 모델 DB(325)에 소스 영상을 입력하고, 학습 모델에서 출력하는 객체 정보를 수신할 수 있다.',\n",
              "  '블록 형태 및 분할 형태는 픽처 또는 슬라이스마다 상이하게 결정되거나, 각각의 최대 부호화 단위마다 상이하게 결정될 수도 있다.']}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_test = preprocess_function(train_ds[:3])\n",
        "print('input id', preprocess_test.input_ids[0])\n",
        "print(tokenizer.decode(preprocess_test.input_ids[0]), '\\n')\n",
        "print('attention mask', preprocess_test.attention_mask[0], '\\n')\n",
        "print('label', preprocess_test.labels[0])\n",
        "print(tokenizer.decode(preprocess_test.labels[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSVtadpAVO79",
        "outputId": "58507621-a464-4ec1-c151-faf1a641bf94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input id [37194, 5413, 288, 259, 37209, 267, 486, 39959, 19002, 259, 175510, 305, 259, 162249, 1432, 390, 17385, 345, 527, 259, 262, 788, 1696, 259, 97359, 2835, 631, 259, 262, 2002, 1233, 525, 2835, 259, 18775, 288, 259, 262, 36577, 260, 1]\n",
            "translate English to Korean: The comparators 1235 and 1237 may be expressed as a Relu activation function or a sigmoid function according to a setting.</s> \n",
            "\n",
            "attention mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
            "\n",
            "label [259, 53789, 1622, 312, 175510, 259, 5593, 644, 101294, 988, 30957, 118645, 259, 18490, 788, 1696, 63019, 3353, 12482, 2277, 1235, 49303, 125462, 1566, 3083, 19023, 261, 6463, 11051, 6763, 63362, 15331, 2277, 1235, 49303, 125462, 259, 44830, 3632, 260, 1]\n",
            "비교기(1235 및 1237)는 설정에 따라 Relu 활성함수로 나타낼 수 있으며, 시그모이드 함수로 나타낼 수도 있다.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = train_ds.map(preprocess_function, batched=True)\n",
        "tokenized_val = val_ds.map(preprocess_function, batched=True)\n",
        "tokenized_train, tokenized_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "f009ddb1e02b41ae814f8877a3eb39cb",
            "d20148c31e4e4bc4b1d459e5a583e5ca",
            "c2b60ad5702d4067be8140e0ebb76fd3",
            "356a637504c3490887f4ca87ac89fd9d",
            "0b1a3b8d994a4d52b92131c09bf66bd0",
            "d58869b913c14840a93d9a1bc2e4acbe",
            "c276c9e132274f42bafeb097772a4e4c",
            "9ee6cd1719ab408a9c8ae779efe80518",
            "89608d0e79ad405ca41205316fcb2f87",
            "96c77d6b89484ca4a05c3b6ba4aae5bc",
            "2ff25790b5714a5591aca9ba63c0232d",
            "820a57d625fa4a9f8fda5c1fc1aac56b",
            "4101b92120a943709e2e6765df6d5aa6",
            "e3b193fbfe7e4cd9bd363692ff88c1dd",
            "a975ac0ec7f040c9ba86e1b00aeba866",
            "d6a890abf12a48a49c58815aa4cd264e",
            "e15522196e104c1887f50c75b284682b",
            "1e74af611db74446a1919ba909a67b12",
            "3ccf19928b9f409496ee05c9d3cadbaf",
            "435165d1ba454725af7e958b87cfa520",
            "eb143de08a61404396c6f46c38b039f9",
            "67840db7811d4ec5a100791ddd797aa5"
          ]
        },
        "id": "uhQB-xQ1VO_N",
        "outputId": "93093eb2-5a5d-4f2e-a6b8-8dd307ac460b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/80 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f009ddb1e02b41ae814f8877a3eb39cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "820a57d625fa4a9f8fda5c1fc1aac56b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['en', 'ko_original', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 79979\n",
              " }), Dataset({\n",
              "     features: ['en', 'ko_original', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 10131\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load metric"
      ],
      "metadata": {
        "id": "MnuWgfC8igUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"sacrebleu\")\n",
        "# fake_preds = [\"hello there\", \"general kenobi\"]\n",
        "# fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n",
        "# metric.compute(predictions=fake_preds, references=fake_labels)"
      ],
      "metadata": {
        "id": "_QjQuaf9O4YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "metadata": {
        "id": "XKXf0rA-gGPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check and Load model"
      ],
      "metadata": {
        "id": "v7YFYMPailL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "pyw5xcgqQUaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_config(config)"
      ],
      "metadata": {
        "id": "q_9rSeWrRKfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Specifics\n",
        "# run_name = \n",
        "# seed = \n",
        "# data_seed = \n",
        "\n",
        "# Dir\n",
        "# report_to = \n",
        "# output_dir = \n",
        "# logging_dir = \n",
        "# overwrite_output_dir = \n",
        "\n",
        "# Hyper Parameters\n",
        "# num_train_epochs = \n",
        "# per_device_train_batch_size = \n",
        "# per_device_eval_batch_size = \n",
        "# gradient_accumulation_steps = \n",
        "# learning_rate = \n",
        "# weight_decay = \n",
        "# adam_beta1 = \n",
        "# adam_beta2 = \n",
        "# adam_epsilon = \n",
        "# max_grad_norm = \n",
        "# lr_scheduler_type = \n",
        "# warmup_ratio = \n",
        "# warmup_steps = \n",
        "# optim = \n",
        "# adafactor = \n",
        "\n",
        "# Eval\n",
        "# predict_with_generate = \n",
        "# generation_max_length = \n",
        "# generation_num_beams = \n",
        "# evaluation_strategy = \n",
        "# eval_delay = \n",
        "# eval_steps = \n",
        "\n",
        "# Logging\n",
        "# logging_strategy = \n",
        "# logging_first_step = \n",
        "# logging_steps = \n",
        "\n",
        "# Archving\n",
        "# save_strategy = \n",
        "# save_steps = \n",
        "# save_total_limit = \n",
        "# load_best_model_at_end = \n",
        "# metric_for_best_model = \n",
        "\n",
        "# etc.\n",
        "# resume_from_checkpoint = \n",
        "# remove_unused_columns = \n",
        "# label_names = \n",
        "# group_by_length = \n",
        "\n",
        "# for System\n",
        "# fp16 = \n",
        "# gradient_checkpointing = \n",
        "\n",
        "\n",
        "\n",
        "# not in use\n",
        "\n",
        "# do_train = \n",
        "# do_eval = \n",
        "# do_predict = \n",
        "# prediction_loss_only = \n",
        "\n",
        "# half_precision_backend = \n",
        "# no_cuda = \n",
        "# jit_mode_eval = \n",
        "# use_ipex = \n",
        "# bf16 = \n",
        "# fp16_opt_level = \n",
        "# bf16_full_eval = \n",
        "# fp16_full_eval = \n",
        "# tf32 = \n",
        "# local_rank = \n",
        "# xpu_backend = \n",
        "# tpu_num_cores = \n",
        "# tpu_metrics_debug = \n",
        "# debug = \n",
        "# dataloader_drop_last = \n",
        "\n",
        "# dataloader_num_workers = \n",
        "# past_index = \n",
        "# disable_tqdm = \n",
        "# greater_is_better = \n",
        "# ignore_data_skip = \n",
        "# sharded_ddp = \n",
        "# fsdp = \n",
        "# fsdp_min_num_params = \n",
        "# fsdp_transformer_layer_cls_to_wrap = \n",
        "# deepspeed = \n",
        "# label_smoothing_factor = \n",
        "\n",
        "# length_column_name = \n",
        "# ddp_find_unused_parameters = \n",
        "# ddp_bucket_cap_mb = \n",
        "# dataloader_pin_memory = \n",
        "# skip_memory_metrics = \n",
        "# use_legacy_prediction_loop = \n",
        "\n",
        "# include_inputs_for_metrics = \n",
        "# fp16_backend = \n",
        "# mp_parameters = \n",
        "# auto_find_batch_size = \n",
        "# full_determinism = \n",
        "# torchdynamo = \n",
        "# ray_scope = \n",
        "# sortish_sampler = \n",
        "\n",
        "# per_gpu_train_batch_size = \n",
        "# per_gpu_eval_batch_size = \n",
        "\n",
        "# max_steps = \n",
        "# log_level = \n",
        "# log_level_replica = \n",
        "# log_on_each_node = \n",
        "# logging_nan_inf_filter = \n",
        "# save_on_each_node = \n",
        "# push_to_hub = \n",
        "# hub_model_id = \n",
        "# hub_strategy = \n",
        "# hub_token = \n",
        "# hub_private_repo = \n",
        "# push_to_hub_model_id = \n",
        "# push_to_hub_organization = \n",
        "# push_to_hub_token = \n",
        "# eval_accumulation_steps = "
      ],
      "metadata": {
        "id": "eYwlo37NuMSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = model_ckpt.split(\"/\")[-1]\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
        "    \n",
        "    report_to='wandb',\n",
        "    run_name=run_name,\n",
        "\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "\n",
        "    evaluation_strategy=evaluation_strategy,\n",
        "    predict_with_generate=predict_with_generate,\n",
        "    generation_max_length=generation_max_length,\n",
        "    \n",
        "    save_strategy=save_strategy,\n",
        "    save_total_limit=save_total_limit,\n",
        "    load_best_model_at_end=load_best_model_at_end,\n",
        "    metric_for_best_model=metric_for_best_model,\n",
        "\n",
        "    save_steps=save_steps,\n",
        "    eval_steps=eval_steps,\n",
        "\n",
        "    logging_strategy=logging_strategy,\n",
        "    logging_first_step=logging_first_step, \n",
        "    logging_steps=logging_steps,\n",
        "    \n",
        "    fp16=fp16,\n",
        ")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "es = EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)"
      ],
      "metadata": {
        "id": "Tzq1F-lNRpLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    # compute_metrics=compute_metrics,\n",
        "    callbacks=[es],\n",
        ")"
      ],
      "metadata": {
        "id": "CFZFoERSgMoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RlgQ_NgChMRy",
        "outputId": "8706b99b-2778-4635-c973-8a3e181fb6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 79979\n",
            "  Num Epochs = 15\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 74970\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220802_090614-20kjnyxk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dotsnangles/en2ko-translator-mt5-small/runs/20kjnyxk\" target=\"_blank\">test run 005</a></strong> to <a href=\"https://wandb.ai/dotsnangles/en2ko-translator-mt5-small\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20277' max='74970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20277/74970 3:00:10 < 8:06:02, 1.88 it/s, Epoch 4.06/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>65.856100</td>\n",
              "      <td>43.687119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>47.047900</td>\n",
              "      <td>35.566174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>39.975400</td>\n",
              "      <td>29.252760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>32.768900</td>\n",
              "      <td>25.246016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>29.025600</td>\n",
              "      <td>21.250271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>24.100300</td>\n",
              "      <td>17.853937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8750</td>\n",
              "      <td>21.614100</td>\n",
              "      <td>15.414333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>18.588700</td>\n",
              "      <td>13.162157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11250</td>\n",
              "      <td>17.003500</td>\n",
              "      <td>11.956568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>15.321100</td>\n",
              "      <td>10.827205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13750</td>\n",
              "      <td>14.524700</td>\n",
              "      <td>9.866852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>13.332000</td>\n",
              "      <td>9.079829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16250</td>\n",
              "      <td>12.527300</td>\n",
              "      <td>8.640100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>11.717100</td>\n",
              "      <td>7.875749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18750</td>\n",
              "      <td>11.301000</td>\n",
              "      <td>7.552176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>10.544100</td>\n",
              "      <td>7.212873</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-1250\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1250/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1250/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1250/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-1250/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-2500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-2500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-3750\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3750/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3750/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3750/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-3750/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-5000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-5000/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-6250\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6250/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6250/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6250/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-6250/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-7500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-7500/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-1250] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-8750\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-8750/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-8750/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-8750/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-8750/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-2500] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-10000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-10000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-10000/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-3750] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-11250\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-11250/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-11250/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-11250/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-11250/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-5000] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-12500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-12500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-12500/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-6250] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-13750\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-13750/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-13750/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-13750/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-13750/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-7500] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-15000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-15000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-15000/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-8750] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-16250\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-16250/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-16250/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-16250/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-16250/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-10000] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-17500\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-17500/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-17500/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-17500/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-17500/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-11250] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-18750\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-18750/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-18750/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-18750/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-18750/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-12500] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `MT5ForConditionalGeneration.forward` and have been ignored: ko_original, en. If ko_original, en are not expected by `MT5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 10131\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to mt5-small-finetuned-en-to-ko_original/checkpoint-20000\n",
            "Configuration saved in mt5-small-finetuned-en-to-ko_original/checkpoint-20000/config.json\n",
            "Model weights saved in mt5-small-finetuned-en-to-ko_original/checkpoint-20000/pytorch_model.bin\n",
            "tokenizer config file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-20000/tokenizer_config.json\n",
            "Special tokens file saved in mt5-small-finetuned-en-to-ko_original/checkpoint-20000/special_tokens_map.json\n",
            "Deleting older checkpoint [mt5-small-finetuned-en-to-ko_original/checkpoint-13750] due to args.save_total_limit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vqenuXm6DCb0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}